{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "65922271-ec83-4572-bffa-b535c99b9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from  buffer import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1eb1619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PASS = 0\n",
    "BET = 1\n",
    "NUM_ACTIONS = 2\n",
    "NUM_PLAYERS = 2\n",
    "nodeMap = {}\n",
    "\n",
    "\n",
    "def getStrategy(infoSet):\n",
    "    encoder = KuhnEncoder()\n",
    "    regrets = tf.reshape(regretNet(encoder.encode(infoSet)), (NUM_ACTIONS,))\n",
    "    regrets = tf.nn.relu(regrets)\n",
    "    strategy, regretSum = tf.linalg.normalize(regrets, ord=1)\n",
    "    if regretSum < 0.01:\n",
    "        strategy, _ = tf.linalg.normalize(np.ones(tf.shape(strategy), dtype=np.float32), ord=1)\n",
    "    return strategy\n",
    "    \n",
    "\n",
    "def getAverageStrategy(infoSet):\n",
    "    encoder = KuhnEncoder()\n",
    "    regrets = tf.reshape(strategyNet(encoder.encode(infoSet)), (NUM_ACTIONS,))\n",
    "    regret_sum = tf.sum(regrets)\n",
    "    \n",
    "\n",
    "def getSample(strategy):\n",
    "    cum_probs = tf.cumsum(strategy)\n",
    "    rand_num = tf.random.uniform([], 0, 1)\n",
    "    i = tf.argmax(cum_probs > rand_num)\n",
    "    return i\n",
    "\n",
    "\n",
    "class KuhnEncoder():\n",
    "    def __init__(self):\n",
    "        self.infostates = pd.Series([\"1\", \"2\", \"3\", \"1p\", \"2p\", \"3p\", \n",
    "                                     \"1b\", \"2b\", \"3b\", \"1pb\", \"2pb\", \"3pb\"])\n",
    "    \n",
    "    def encode(self, infoState):\n",
    "        return np.array(self.infostates == infoState).astype(float)\n",
    "\n",
    "\n",
    "def IsTerminal(cards, history, player):\n",
    "    plays = len(history)\n",
    "    opponent = 1 - player\n",
    "    if plays > 1 :\n",
    "        terminalPass = history[-1] == \"p\"\n",
    "        doubleBet = history[-2:] == \"bb\"\n",
    "        isPlayerCardHigher = cards[player] > cards[opponent]\n",
    "        if terminalPass:\n",
    "            if history == \"pp\":\n",
    "                return 1 if isPlayerCardHigher else -1\n",
    "            else:\n",
    "                return 1\n",
    "        elif doubleBet:\n",
    "            return 2 if isPlayerCardHigher else -2\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f3821b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(buffer, validation_fraction=3/4):\n",
    "    x, y = [], []\n",
    "    \n",
    "    splitIdx = int(buffer.size * validation_fraction)\n",
    "    for (i, t, sigma) in buffer.data:\n",
    "        x.append(KuhnEncoder().encode(i))\n",
    "        y.append(sigma)\n",
    "    x, y = np.array(x), np.array(y)\n",
    "    return (x[:splitIdx], y[:splitIdx]), (x[splitIdx:], y[splitIdx:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "53cdb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(cards, history, traversingPlayer, time, valueBuffer, strategyBuffer):\n",
    "    plays = len(history)\n",
    "    player = plays % 2\n",
    "    infoSet = str(cards[player]) + history\n",
    "    strategy = getStrategy(infoSet)\n",
    "\n",
    "    if(IsTerminal(cards, history, traversingPlayer) is not None):\n",
    "        return IsTerminal(cards, history, traversingPlayer)\n",
    "    elif player == traversingPlayer:\n",
    "        nodeUtil = 0\n",
    "        util = [0 for _ in range(NUM_ACTIONS)]\n",
    "        regret = [0 for _ in range(NUM_ACTIONS)]\n",
    "        for a in range(NUM_ACTIONS):\n",
    "            nextHistory = history + ('p' if a == PASS else 'b')\n",
    "            util[a] = traverse(cards, nextHistory, traversingPlayer, time, \n",
    "                valueBuffer, strategyBuffer)\n",
    "            nodeUtil += util[a] * strategy[a]\n",
    "        for a in range(NUM_ACTIONS):\n",
    "            regret[a] = util[a] - nodeUtil\n",
    "            valueBuffer.insert((infoSet, time, regret))\n",
    "        return nodeUtil\n",
    "    else:\n",
    "        strategyBuffer.insert((infoSet, time, strategy))\n",
    "        a = getSample(strategy)\n",
    "        nextHistory = history + ('p' if a == PASS else 'b')\n",
    "        return traverse(cards, nextHistory, traversingPlayer, time, \n",
    "                        valueBuffer, strategyBuffer)\n",
    "\n",
    "\n",
    "def train(inner_iterations, outer_iterations):\n",
    "    stratBuffer = ReplayBuffer(30)\n",
    "    regretNet = keras.Sequential([\n",
    "        keras.layers.Normalization(input_shape=[12, ]),\n",
    "        keras.layers.Dense(30, activation=\"relu\"),\n",
    "        keras.layers.Dense(30, activation=\"relu\"),\n",
    "        keras.layers.Dense(2)\n",
    "    ])\n",
    "    strategyNet = keras.Sequential([\n",
    "        keras.layers.Normalization(input_shape=[12, ]),\n",
    "        keras.layers.Dense(30, activation=\"relu\"),\n",
    "        keras.layers.Dense(30, activation=\"relu\"),\n",
    "        keras.layers.Dense(2, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    regretNet.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=keras.losses.MeanSquaredError(),\n",
    "    )\n",
    "    \n",
    "    strategyNet.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "    )\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(outer_iterations):\n",
    "        valBuffer = ReplayBuffer(30)\n",
    "        for j in range(inner_iterations):\n",
    "            cards = [1, 2, 3]\n",
    "            random.shuffle(cards)\n",
    "            \n",
    "            for traversingPlayer in range(NUM_PLAYERS): \n",
    "                traverse(cards, '', traversingPlayer, j, valBuffer, stratBuffer)\n",
    "        \n",
    "        (x_train, y_train), (x_val, y_val) = generateDataset(valBuffer)\n",
    "        regretNet.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=8,\n",
    "            epochs=5,\n",
    "            validation_data=(x_val,y_val)\n",
    "        )\n",
    "    \n",
    "    print(\"Finally, training the strategy.\")\n",
    "    (x_train, y_train), (x_val, y_val) = generateDataset(stratBuffer)\n",
    "    strategyNet.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=8,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val,y_val)\n",
    "    )\n",
    "        \n",
    "    # train strategy net\n",
    "    return valBuffer, stratBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "144ff951-20a8-4815-968f-66e7c9639d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 2s 230ms/step - loss: 1.1485 - mean_squared_error: 1.2250 - val_loss: 1.6818 - val_mean_squared_error: 1.6818\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.0907 - mean_squared_error: 1.1628 - val_loss: 1.6549 - val_mean_squared_error: 1.6549\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0579 - mean_squared_error: 1.1004 - val_loss: 1.6339 - val_mean_squared_error: 1.6339\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0329 - mean_squared_error: 1.0110 - val_loss: 1.6187 - val_mean_squared_error: 1.6187\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0078 - mean_squared_error: 0.9524 - val_loss: 1.6048 - val_mean_squared_error: 1.6048\n",
      "Finally, training the strategy.\n",
      "3/3 [==============================] - 5s 109ms/step - loss: 0.1615 - val_loss: 0.1494\n"
     ]
    }
   ],
   "source": [
    "_, buffer = train(50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfeaeea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
